C:\ReactProjects\LeviatanCode [Leviatancode2.0 â†‘17 +25 ~0 -0 !]> python .\scripts\start-with-secrets-manager.py
18:31:08 ğŸ”§ [System] Starting LeviatanCode with Secrets Manager...
============================================================
ğŸ” Primary method: Encrypted Secrets Vault
Enter master password for secrets vault: rPqIaDiGvzR9pQJRrcdmB3pEe
âœ… Loaded 10 secrets from vault
âœ… Using encrypted vault as primary configuration source

[1/4] Starting Ollama AI Worker...
18:31:24 ğŸ¦™ [Ollama] Starting Ollama service...
18:31:24 ğŸ¦™ [Ollama] Ollama worker started in background

[2/4] Starting Flask Analyzer...
[3/4] Waiting for Flask at http://127.0.0.1:5001/health...
INFO:app:Starting LeviatanCode Flask Analyzer API
INFO:app:Server running on: http://localhost:5001
INFO:app:Debug mode: True
INFO:app:OpenAI API configured: True
INFO:app:Gemini API configured: True
INFO:app:Ready to analyze projects!
 * Serving Flask app 'app'
 * Debug mode: on
INFO:werkzeug:WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://10.119.4.204:5001
INFO:werkzeug:Press CTRL+C to quit
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:app:Starting LeviatanCode Flask Analyzer API
INFO:app:Server running on: http://localhost:5001
INFO:app:Debug mode: True
INFO:app:OpenAI API configured: True
INFO:app:Gemini API configured: True
INFO:app:Ready to analyze projects!
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 140-576-213
INFO:werkzeug:127.0.0.1 - - [11/Aug/2025 18:31:26] "GET /health HTTP/1.1" 200 -
âœ… Flask is ready!

[4/4] Starting main application...
18:31:26 ğŸ”§ [System] AI Dual Mode: ChatGPT (architecture) + Ollama Llama3 (development)
18:31:27 ğŸ¦™ [Ollama] Ollama service is ready!
18:31:27 ğŸ¦™ [Ollama] Checking Llama3 model availability...
18:31:29 ğŸ¦™ [Ollama] Llama3 model already available
18:31:29 ğŸ¦™ [Ollama] Ollama worker ready - AI dual mode available
[dotenv@17.2.1] injecting env (0) from .env -- tip: ğŸ“¡ auto-backup env with Radar: https://dotenvx.com/radar
ğŸ” Database URL configured: postgresql://postgres.zlyhdlfiwzmlsarfvoqw:uQV710B...
[dotenv@17.2.1] injecting env (0) from .env -- tip: âš™ï¸  enable debug logging with { debug: true }
[INFO] Environment: development
ğŸ” Testing database connection...
INFO:werkzeug:127.0.0.1 - - [11/Aug/2025 18:31:31] "GET /health HTTP/1.1" 200 -
18:31:31 âš™ï¸ [Middleware] All middleware loaded successfully with monitoring
18:31:31 ğŸ—„ï¸ [Database] Testing database connection...
ğŸ” Testing database connection...
âœ… Database connection successful: { test: 1 }
18:31:32 ğŸ—„ï¸ [Database] Database storage initialized
âœ… Database connection successful: { test: 1 }
ğŸ—„ï¸  Attempting to use database storage (Supabase)...
6:31:32 PM [express] serving on port 5005
18:31:32 ğŸ [Flask] Auto-starting Flask Analyzer...
ğŸ”„ Starting Flask Analyzer service...
ğŸ“¦ Installing Flask dependencies...
Warning: Could not setup virtual environment, trying system Python: Error: Command failed: cd flask_analyzer && flask_analyzer\venv\Scripts\pip install flask flask-cors requests werkzeug --quiet
The system cannot find the path specified.

    at genericNodeError (node:internal/errors:983:15)
    at wrappedFn (node:internal/errors:537:14)
    at ChildProcess.exithandler (node:child_process:414:12)
    at ChildProcess.emit (node:events:518:28)
    at maybeClose (node:internal/child_process:1101:16)
    at Socket.<anonymous> (node:internal/child_process:456:11)
    at Socket.emit (node:events:518:28)
    at Pipe.<anonymous> (node:net:351:12) {
  code: 1,
  killed: false,
  signal: null,
  cmd: 'cd flask_analyzer && flask_analyzer\\venv\\Scripts\\pip install flask flask-cors requests werkzeug --quiet',
  stdout: '',
  stderr: 'The system cannot find the path specified.\r\n'
}
ğŸ“¦ Installing minimal Flask dependencies with system Python...
âœ… Minimal Flask dependencies installed with system Python
ğŸš€ Starting Flask server with command: cd flask_analyzer && start_flask.bat
18:31:33 ğŸ [Flask] Flask Analyzer startup initiated, waiting for service to be ready...
INFO:werkzeug:127.0.0.1 - - [11/Aug/2025 18:31:33] "GET /health HTTP/1.1" 200 -
18:31:33 ğŸ [Flask] Flask Analyzer is ready and responding
18:31:33 ğŸ”§ [System] Main application startup complete
Flask stdout: Starting Flask Analyzer for Windows...

Flask stdout: Installing Flask dependencies...

Flask stdout: Checking virtual environment...

Flask stdout: Using virtual environment

Flask stderr: No Python a
Flask stderr: t '"/nix/store/2lcqw1d28vklbk8ikiwad28iq2smwndv-python-wrapped-0.1.0/bin\python.exe'

Flask Analyzer process exited with code 103
Flask Analyzer start error: Error: Command failed: cd flask_analyzer && start_flask.bat
No Python at '"/nix/store/2lcqw1d28vklbk8ikiwad28iq2smwndv-python-wrapped-0.1.0/bin\python.exe'

    at genericNodeError (node:internal/errors:983:15)
    at wrappedFn (node:internal/errors:537:14)
    at ChildProcess.exithandler (node:child_process:414:12)
    at ChildProcess.emit (node:events:518:28)
    at maybeClose (node:internal/child_process:1101:16)
    at ChildProcess._handle.onexit (node:internal/child_process:304:5) {
  code: 103,
  killed: false,
  signal: null,
  cmd: 'cd flask_analyzer && start_flask.bat'
}
INFO:werkzeug:127.0.0.1 - - [11/Aug/2025 18:31:36] "GET /health HTTP/1.1" 200 -
18:31:59 ğŸ¦™ [Ollama] Ollama service stopped unexpectedly
INFO:werkzeug:127.0.0.1 - - [11/Aug/2025 18:32:01] "GET /health HT