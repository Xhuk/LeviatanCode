#!/usr/bin/env python3
"""
Intelligent Project Analysis Script for LeviatanCode
Generated by LeviatanCode AI

This script analyzes project structure, detects technologies, creates file trees,
and integrates with Gemini AI for comprehensive insights.
"""

import os
import json
import requests
from pathlib import Path
from typing import Dict, List, Any, Optional
import datetime
import subprocess
import re

class ProjectAnalyzer:
    def __init__(self, project_path: str, gemini_api_key: Optional[str] = None):
        self.project_path = Path(project_path)
        self.gemini_api_key = gemini_api_key or os.getenv('GEMINI_API_KEY')
        self.analysis_data = {
            "project_name": "LeviatanCode",
            "analysis_date": datetime.datetime.now().isoformat(),
            "project_path": str(self.project_path.absolute()),
            "file_tree": {},
            "file_types": {},
            "technologies": [],
            "frameworks": [],
            "dependencies": {},
            "package_managers": [],
            "build_tools": [],
            "configuration_files": [],
            "documentation_files": [],
            "test_files": [],
            "source_files": [],
            "asset_files": [],
            "total_files": 0,
            "total_size": 0,
            "lines_of_code": 0
        }

    def create_file_tree(self) -> Dict[str, Any]:
        """Create a detailed file tree structure."""
        def build_tree(path: Path, max_depth: int = 5, current_depth: int = 0) -> Dict[str, Any]:
            if current_depth >= max_depth:
                return {"...": "max_depth_reached"}
            
            tree = {}
            try:
                items = sorted(path.iterdir(), key=lambda x: (x.is_file(), x.name.lower()))
                for item in items:
                    # Skip hidden files and common build directories
                    if item.name.startswith('.') and item.name not in ['.env', '.gitignore', '.dockerignore']:
                        continue
                    if item.name in ['node_modules', '__pycache__', 'dist', 'build', 'target', 'bin', 'obj', '.git']:
                        continue
                    
                    if item.is_file():
                        file_size = item.stat().st_size
                        tree[item.name] = {
                            "type": "file",
                            "size": file_size,
                            "extension": item.suffix.lower(),
                            "modified": datetime.datetime.fromtimestamp(item.stat().st_mtime).isoformat()
                        }
                        self.analysis_data["total_files"] += 1
                        self.analysis_data["total_size"] += file_size
                        
                        # Count lines of code for text files
                        if self.is_text_file(item):
                            try:
                                with open(item, 'r', encoding='utf-8', errors='ignore') as f:
                                    lines = len(f.readlines())
                                    tree[item.name]["lines"] = lines
                                    self.analysis_data["lines_of_code"] += lines
                            except:
                                pass
                    
                    elif item.is_dir():
                        tree[item.name] = {
                            "type": "directory",
                            "contents": build_tree(item, max_depth, current_depth + 1)
                        }
            except PermissionError:
                tree["[Permission Denied]"] = {"type": "error"}
            
            return tree
        
        return build_tree(self.project_path)

    def detect_technologies(self) -> None:
        """Detect technologies, frameworks, and tools used in the project."""
        technology_indicators = {
            # Languages
            'JavaScript': ['.js', '.mjs'],
            'TypeScript': ['.ts', '.tsx'],
            'Python': ['.py', '.pyw'],
            'Java': ['.java', '.jar'],
            'C#': ['.cs', '.csproj'],
            'C++': ['.cpp', '.cc', '.cxx', '.h', '.hpp'],
            'C': ['.c', '.h'],
            'Go': ['.go'],
            'Rust': ['.rs'],
            'PHP': ['.php'],
            'Ruby': ['.rb'],
            'Swift': ['.swift'],
            'Kotlin': ['.kt'],
            'Dart': ['.dart'],
            'HTML': ['.html', '.htm'],
            'CSS': ['.css', '.scss', '.sass', '.less'],
            'SQL': ['.sql'],
            'Shell': ['.sh', '.bash', '.zsh'],
            'PowerShell': ['.ps1'],
            'Batch': ['.bat', '.cmd']
        }
        
        framework_files = {
            # Package managers and config files
            'package.json': 'Node.js/npm',
            'yarn.lock': 'Yarn',
            'requirements.txt': 'Python pip',
            'Pipfile': 'Python Pipenv',
            'pyproject.toml': 'Python Poetry',
            'Cargo.toml': 'Rust Cargo',
            'pom.xml': 'Java Maven',
            'build.gradle': 'Java Gradle',
            'composer.json': 'PHP Composer',
            'Gemfile': 'Ruby Bundler',
            'go.mod': 'Go Modules',
            
            # Framework indicators
            'angular.json': 'Angular',
            'vue.config.js': 'Vue.js',
            'nuxt.config.js': 'Nuxt.js',
            'next.config.js': 'Next.js',
            'gatsby-config.js': 'Gatsby',
            'svelte.config.js': 'Svelte',
            'vite.config.js': 'Vite',
            'webpack.config.js': 'Webpack',
            'rollup.config.js': 'Rollup',
            'tsconfig.json': 'TypeScript',
            'tailwind.config.js': 'Tailwind CSS',
            
            # Backend frameworks
            'django': 'Django',
            'flask': 'Flask',
            'fastapi': 'FastAPI',
            'express': 'Express.js',
            'spring': 'Spring Framework',
            'laravel': 'Laravel',
            'rails': 'Ruby on Rails',
            
            # Database
            'docker-compose.yml': 'Docker',
            'Dockerfile': 'Docker',
            'kubernetes': 'Kubernetes',
            '.env': 'Environment Configuration'
        }
        
        # Analyze file extensions
        for file_path in self.project_path.rglob('*'):
            if file_path.is_file():
                ext = file_path.suffix.lower()
                self.analysis_data["file_types"][ext] = self.analysis_data["file_types"].get(ext, 0) + 1
                
                # Categorize files
                if ext in ['.py', '.js', '.ts', '.java', '.cs', '.cpp', '.c', '.go', '.rs', '.php', '.rb']:
                    self.analysis_data["source_files"].append(str(file_path.relative_to(self.project_path)))
                elif ext in ['.md', '.txt', '.rst', '.pdf']:
                    self.analysis_data["documentation_files"].append(str(file_path.relative_to(self.project_path)))
                elif 'test' in file_path.name.lower() or 'spec' in file_path.name.lower():
                    self.analysis_data["test_files"].append(str(file_path.relative_to(self.project_path)))
                elif ext in ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.ico', '.css', '.scss']:
                    self.analysis_data["asset_files"].append(str(file_path.relative_to(self.project_path)))
                
                # Detect technologies by extension
                for tech, extensions in technology_indicators.items():
                    if ext in extensions and tech not in self.analysis_data["technologies"]:
                        self.analysis_data["technologies"].append(tech)
                
                # Detect frameworks by filename
                filename = file_path.name.lower()
                for indicator, framework in framework_files.items():
                    if indicator in filename and framework not in self.analysis_data["frameworks"]:
                        self.analysis_data["frameworks"].append(framework)
                        if indicator in ['package.json', 'yarn.lock', 'requirements.txt', 'Cargo.toml']:
                            self.analysis_data["package_managers"].append(framework)
                        if 'config' in indicator:
                            self.analysis_data["configuration_files"].append(str(file_path.relative_to(self.project_path)))

    def analyze_dependencies(self) -> None:
        """Analyze project dependencies from various package managers."""
        # Node.js dependencies
        package_json = self.project_path / 'package.json'
        if package_json.exists():
            try:
                with open(package_json, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.analysis_data["dependencies"]["npm"] = {
                        "dependencies": data.get("dependencies", {}),
                        "devDependencies": data.get("devDependencies", {}),
                        "scripts": data.get("scripts", {})
                    }
            except:
                pass
        
        # Python dependencies
        requirements_txt = self.project_path / 'requirements.txt'
        if requirements_txt.exists():
            try:
                with open(requirements_txt, 'r', encoding='utf-8') as f:
                    deps = [line.strip() for line in f if line.strip() and not line.startswith('#')]
                    self.analysis_data["dependencies"]["pip"] = deps
            except:
                pass

    def is_text_file(self, file_path: Path) -> bool:
        """Check if a file is a text file."""
        text_extensions = {'.txt', '.md', '.py', '.js', '.ts', '.html', '.css', '.json', '.xml', '.yml', '.yaml', '.toml', '.ini', '.cfg', '.conf', '.sh', '.bat', '.ps1', '.sql', '.php', '.rb', '.go', '.rs', '.java', '.cs', '.cpp', '.c', '.h', '.hpp'}
        return file_path.suffix.lower() in text_extensions

    def generate_gemini_analysis(self) -> Dict[str, Any]:
        """Use Gemini AI to analyze the project structure and provide insights."""
        if not self.gemini_api_key:
            return {"error": "Gemini API key not provided"}
        
        analysis_prompt = f"""
        Analyze this project structure and provide detailed insights:
        
        Project: {self.analysis_data['project_name']}
        Technologies: {', '.join(self.analysis_data['technologies'])}
        Frameworks: {', '.join(self.analysis_data['frameworks'])}
        Total Files: {self.analysis_data['total_files']}
        Lines of Code: {self.analysis_data['lines_of_code']}
        File Types: {json.dumps(self.analysis_data['file_types'], indent=2)}
        Dependencies: {json.dumps(self.analysis_data['dependencies'], indent=2)}
        
        Provide a comprehensive analysis including:
        1. Project type and architecture assessment
        2. Technology stack evaluation
        3. Code quality observations
        4. Security considerations
        5. Performance recommendations
        6. Deployment suggestions
        7. Development workflow improvements
        8. Specific actionable recommendations
        
        Return as JSON with keys: architecture, evaluation, quality, security, performance, deployment, workflow, recommendations
        """
        
        try:
            url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent"
            headers = {
                "Content-Type": "application/json",
                "x-goog-api-key": self.gemini_api_key
            }
            data = {
                "contents": [{
                    "parts": [{"text": analysis_prompt}]
                }]
            }
            
            response = requests.post(url, headers=headers, json=data)
            if response.status_code == 200:
                result = response.json()
                gemini_text = result["candidates"][0]["content"]["parts"][0]["text"]
                
                # Try to extract JSON from response
                try:
                    import re
                    json_match = re.search(r'\{.*\}', gemini_text, re.DOTALL)
                    if json_match:
                        return json.loads(json_match.group())
                    else:
                        return {"raw_analysis": gemini_text}
                except:
                    return {"raw_analysis": gemini_text}
            else:
                return {"error": f"Gemini API error: {response.status_code}"}
        except Exception as e:
            return {"error": f"Failed to connect to Gemini: {str(e)}"}

    def run_analysis(self) -> Dict[str, Any]:
        """Run complete project analysis."""
        print(f"ğŸ” Analyzing project: {self.project_path}")
        print("ğŸ“ Creating file tree...")
        self.analysis_data["file_tree"] = self.create_file_tree()
        
        print("ğŸ”§ Detecting technologies...")
        self.detect_technologies()
        
        print("ğŸ“¦ Analyzing dependencies...")
        self.analyze_dependencies()
        
        print("ğŸ¤– Generating AI insights...")
        gemini_analysis = self.generate_gemini_analysis()
        self.analysis_data["ai_insights"] = gemini_analysis
        
        return self.analysis_data

def main():
    """Main function to run the analysis."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Intelligent Project Analysis Tool')
    parser.add_argument('path', nargs='?', default='.', help='Project path to analyze')
    parser.add_argument('--api-key', help='Gemini API key for AI analysis')
    parser.add_argument('--output', default='LeviatanCode_analysis.json', help='Output file path')
    
    args = parser.parse_args()
    
    analyzer = ProjectAnalyzer(args.path, args.api_key)
    results = analyzer.run_analysis()
    
    # Save results
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… Analysis complete!")
    print(f"ğŸ“Š Results saved to: {args.output}")
    print(f"ğŸ“ Total files: {results['total_files']}")
    print(f"ğŸ’» Technologies: {', '.join(results['technologies'])}")
    print(f"ğŸ› ï¸  Frameworks: {', '.join(results['frameworks'])}")
    print(f"ğŸ“ Lines of code: {results['lines_of_code']:,}")
    
    if results.get('ai_insights') and not results['ai_insights'].get('error'):
        print("ğŸ¤– AI analysis completed successfully!")
    else:
        print("âš ï¸  AI analysis failed - provide GEMINI_API_KEY for enhanced insights")

if __name__ == "__main__":
    main()
